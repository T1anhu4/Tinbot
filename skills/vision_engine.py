"""
Vision Engine - æ”¯æŒå¤šç§å¤šæ¨¡æ€ API
æ”¯æŒï¼šOpenAI GPT-4o, Qwen-VL-MAX, Google Gemini, Anthropic Claude
"""

import pyautogui
import base64
import time
import json
import re
from io import BytesIO
from PIL import Image


class VisionEngine:
    """
    è§†è§‰å¼•æ“
    åŠŸèƒ½ï¼šæˆªå›¾ã€åˆ†æ UIã€å®šä½å…ƒç´ ã€ç‚¹å‡»æ“ä½œ
    æ”¯æŒå¤šç§å¤šæ¨¡æ€ API
    """
    
    def __init__(self, llm_client, model_name="qwen-vl-max", api_type="qwen"):
        """
        åˆå§‹åŒ–è§†è§‰å¼•æ“
        
        Args:
            llm_client: API å®¢æˆ·ç«¯å®ä¾‹ (OpenAI å…¼å®¹æ ¼å¼)
            model_name: æ¨¡å‹åç§°
            api_type: API ç±»å‹ ("openai", "qwen", "gemini", "anthropic")
        """
        self.llm = llm_client
        self.model_name = model_name
        self.api_type = api_type.lower()
        self.screen_width, self.screen_height = pyautogui.size()
        
        # è§†è§‰ç¼“å­˜
        self.last_screenshot = None
        self.last_screenshot_time = 0
        self.cache_duration = 2  # ç¼“å­˜2ç§’
        
        print(f"[VisionEngine] åˆå§‹åŒ–å®Œæˆ")
        print(f"  æ¨¡å‹: {model_name}")
        print(f"  APIç±»å‹: {api_type}")
    
    def capture_screen(self, use_cache=True):
        """
        æˆªå–å½“å‰å±å¹•å¹¶è½¬ Base64
        
        Args:
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            
        Returns:
            tuple: (base64å­—ç¬¦ä¸², å›¾ç‰‡å°ºå¯¸)
        """
        # æ£€æŸ¥ç¼“å­˜
        if use_cache and self.last_screenshot:
            if time.time() - self.last_screenshot_time < self.cache_duration:
                return self.last_screenshot
        
        # æˆªå›¾
        screenshot = pyautogui.screenshot()
        
        # å‹ç¼©å›¾ç‰‡ï¼ˆé™ä½ token æ¶ˆè€—ï¼‰
        screenshot.thumbnail((1280, 720), Image.Resampling.LANCZOS)
        
        # è½¬ Base64
        buffered = BytesIO()
        screenshot.save(buffered, format="JPEG", quality=85)
        b64_img = base64.b64encode(buffered.getvalue()).decode()
        
        # æ›´æ–°ç¼“å­˜
        self.last_screenshot = (b64_img, screenshot.size)
        self.last_screenshot_time = time.time()
        
        return b64_img, screenshot.size
    
    def _call_qwen_vision(self, b64_img, prompt):
        """
        è°ƒç”¨ Qwen-VL-MAX (é€šä¹‰åƒé—®å¤šæ¨¡æ€)
        
        Qwen-VL ä½¿ç”¨ OpenAI å…¼å®¹çš„ API æ ¼å¼
        """
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ UI è§†è§‰åˆ†æåŠ©æ‰‹ã€‚
ä½ çš„ä»»åŠ¡æ˜¯åˆ†æå±å¹•æˆªå›¾å¹¶å®šä½ UI å…ƒç´ ã€‚

**è¿”å›æ ¼å¼ï¼ˆä¸¥æ ¼ JSONï¼‰:**
{
    "action": "click",
    "coordinates": [x, y],
    "text_content": "è¯†åˆ«åˆ°çš„æ–‡å­—å†…å®¹",
    "confidence": 0.95
}

**é‡è¦è¯´æ˜:**
- coordinates å¿…é¡»æ˜¯å½’ä¸€åŒ–åæ ‡ï¼ŒèŒƒå›´ 0-1
- [0, 0] ä»£è¡¨å·¦ä¸Šè§’
- [1, 1] ä»£è¡¨å³ä¸‹è§’
- [0.5, 0.5] ä»£è¡¨å±å¹•æ­£ä¸­å¿ƒ
- è¯·åŠ¡å¿…è¿”å›çº¯ JSONï¼Œä¸è¦åŒ…å«ä»»ä½•é¢å¤–çš„æ–‡å­—è¯´æ˜
"""
        
        # Qwen-VL-MAX çš„æ¶ˆæ¯æ ¼å¼
        messages = [
            {
                "role": "system",
                "content": system_prompt
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{b64_img}"
                        }
                    },
                    {
                        "type": "text",
                        "text": prompt
                    }
                ]
            }
        ]
        
        try:
            response = self.llm.chat.completions.create(
                model=self.model_name,
                messages=messages,
                max_tokens=1000,
                temperature=0.1
            )
            
            return response.choices[0].message.content
        
        except Exception as e:
            print(f"âŒ Qwen-VL API è°ƒç”¨å¤±è´¥: {e}")
            raise
    
    def analyze_ui(self, prompt_instruction, use_cache=True):
        """
        åˆ†æ UI ç•Œé¢
        
        Args:
            prompt_instruction: æŒ‡ä»¤
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            
        Returns:
            dict: åˆ†æç»“æœ
        """
        b64_img, img_size = self.capture_screen(use_cache)
        
        print(f"ğŸ‘ï¸ [VisionEngine] æ­£åœ¨åˆ†æ: {prompt_instruction}...")
        
        try:
            # è°ƒç”¨ Qwen-VL
            content = self._call_qwen_vision(b64_img, prompt_instruction)
            
            # è§£æ JSON
            result = self._parse_vision_response(content)
            
            if result["confidence"] < 0.5:
                print(f"âš ï¸ [VisionEngine] ä½ç½®ä¿¡åº¦: {result['confidence']}")
            
            return result
        
        except Exception as e:
            print(f"âŒ [VisionEngine] è§†è§‰åˆ†æå¤±è´¥: {e}")
            return {
                "action": "error",
                "coordinates": [0.5, 0.5],
                "text_content": f"åˆ†æå¤±è´¥: {str(e)}",
                "confidence": 0
            }
    
    def _parse_vision_response(self, content):
        """è§£æ LLM çš„è§†è§‰å“åº”"""
        try:
            # æ¸…æ´— JSONï¼ˆç§»é™¤ Markdown åŒ…è£¹ï¼‰
            content = re.sub(r'```json\s*|\s*```', '', content).strip()
            
            # æå–ç¬¬ä¸€ä¸ªå®Œæ•´çš„ JSON å¯¹è±¡
            start = content.find('{')
            if start != -1:
                stack = 0
                for i in range(start, len(content)):
                    if content[i] == '{':
                        stack += 1
                    elif content[i] == '}':
                        stack -= 1
                        if stack == 0:
                            json_str = content[start:i+1]
                            parsed = json.loads(json_str)
                            
                            # éªŒè¯å¿…éœ€å­—æ®µ
                            if "coordinates" not in parsed:
                                raise ValueError("ç¼ºå°‘ coordinates å­—æ®µ")
                            
                            # è®¾ç½®é»˜è®¤å€¼
                            if "confidence" not in parsed:
                                parsed["confidence"] = 0.8
                            if "text_content" not in parsed:
                                parsed["text_content"] = ""
                            if "action" not in parsed:
                                parsed["action"] = "click"
                            
                            return parsed
            
            raise ValueError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ JSON")
        
        except Exception as e:
            print(f"âŒ JSON è§£æå¤±è´¥: {e}")
            print(f"åŸå§‹å†…å®¹: {content[:200]}...")
            return {
                "action": "error",
                "coordinates": [0.5, 0.5],
                "text_content": content[:200],
                "confidence": 0
            }
    
    def click_element(self, element_description, double_click=False, retry=3):
        """
        ç‚¹å‡» UI å…ƒç´ 
        
        Args:
            element_description: å…ƒç´ æè¿°
            double_click: æ˜¯å¦åŒå‡»
            retry: é‡è¯•æ¬¡æ•°
        """
        for attempt in range(retry):
            try:
                result = self.analyze_ui(
                    f"è¯·æ‰¾åˆ°å±å¹•ä¸Šçš„ '{element_description}' å¹¶è¿”å›å…¶ä¸­å¿ƒç‚¹ä½ç½®ã€‚",
                    use_cache=(attempt == 0)
                )
                
                if result["confidence"] < 0.5:
                    if attempt < retry - 1:
                        print(f"âš ï¸ ç½®ä¿¡åº¦è¿‡ä½ï¼Œé‡è¯• ({attempt + 1}/{retry})...")
                        time.sleep(1)
                        continue
                    else:
                        return f"âŒ æœªæ‰¾åˆ°å…ƒç´ : {element_description}"
                
                # è½¬æ¢åæ ‡
                norm_x, norm_y = result["coordinates"]
                real_x = int(norm_x * self.screen_width)
                real_y = int(norm_y * self.screen_height)
                
                # è¾¹ç•Œæ£€æŸ¥
                real_x = max(0, min(real_x, self.screen_width - 1))
                real_y = max(0, min(real_y, self.screen_height - 1))
                
                # ç§»åŠ¨å¹¶ç‚¹å‡»
                pyautogui.moveTo(real_x, real_y, duration=0.5)
                time.sleep(0.2)
                
                if double_click:
                    pyautogui.doubleClick()
                else:
                    pyautogui.click()
                
                return f"âœ… å·²ç‚¹å‡» '{element_description}' (åæ ‡: {real_x}, {real_y}, ç½®ä¿¡åº¦: {result['confidence']:.2f})"
            
            except Exception as e:
                if attempt < retry - 1:
                    print(f"âŒ ç‚¹å‡»å¤±è´¥ï¼Œé‡è¯• ({attempt + 1}/{retry}): {e}")
                    time.sleep(1)
                else:
                    return f"âŒ ç‚¹å‡»å¤±è´¥: {str(e)}"
        
        return f"âŒ è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°"
    
    def read_screen_text(self, area_description="æ•´ä¸ªå±å¹•"):
        """è¯»å–å±å¹•æ–‡å­—"""
        result = self.analyze_ui(
            f"è¯·è¯†åˆ« {area_description} ä¸Šçš„æ‰€æœ‰æ–‡å­—å†…å®¹ï¼ŒæŒ‰ä»ä¸Šåˆ°ä¸‹ã€ä»å·¦åˆ°å³çš„é¡ºåºåˆ—å‡ºã€‚"
        )
        
        return result.get("text_content", "")
    
    def find_element_position(self, element_description):
        """æŸ¥æ‰¾å…ƒç´ ä½ç½®"""
        result = self.analyze_ui(f"è¯·æ‰¾åˆ° '{element_description}' çš„ä½ç½®")
        
        if result["confidence"] > 0.5:
            norm_x, norm_y = result["coordinates"]
            real_x = int(norm_x * self.screen_width)
            real_y = int(norm_y * self.screen_height)
            return (real_x, real_y, result["confidence"])
        
        return None